# AI News Event Analysis System

An intelligent news aggregation and analysis tool powered by DeepSeek-V3, implementing Map-Reduce architecture for automated multi-source news collection, deduplication, summarization, and visualization report generation.

[ä¸­æ–‡æ–‡æ¡£](README.md) | **English**

## Features

- ğŸ” **Multi-Source Search**: Supports Google + Baidu News + Bing triple-engine intelligent search (Google Cookie configurable)
- ğŸ“„ **Smart Crawling**: Dual-mode crawling with static (Newspaper3k) and dynamic (Selenium) crawlers
- ğŸ§¹ **Fuzzy Deduplication**: Intelligent title deduplication based on FuzzyWuzzy (85% threshold)
- ğŸ¤– **AI Analysis**: DeepSeek-V3 powered Map-Reduce summarization
- ğŸ“Š **Visual Reports**: Generates beautiful dark-themed HTML reports
- ğŸ–¥ï¸ **GUI Interface**: User-friendly interface based on PyQt6
- ğŸš€ **Auto Fallback**: Automatically switches to dynamic crawler when static crawler fails

## Project Structure

```
news_analyzer/
â”œâ”€â”€ main.py                 # Program entry
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .env                   # Environment variables (create manually)
â”œâ”€â”€ core/                  # Core modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ searcher.py        # News search
â”‚   â”œâ”€â”€ crawler.py         # Article crawling & deduplication
â”‚   â”œâ”€â”€ analyzer.py        # AI analysis (Map-Reduce)
â”‚   â””â”€â”€ reporter.py        # HTML report generation
â”œâ”€â”€ gui/                   # GUI modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ window.py          # Main window
â”‚   â””â”€â”€ worker.py          # Background worker thread
â”œâ”€â”€ templates/             # Template files
â”‚   â””â”€â”€ report_template.py # HTML report template
â””â”€â”€ reports/               # Generated reports (auto-created)
    â””â”€â”€ *.html             # HTML report files
```

## Installation

1. Clone the project
```bash
git clone https://github.com/SHANECHEN0722/news_seacher.git
cd news_analyzer
```

2. Install dependencies
```bash
pip install -r requirements.txt
```

3. Configure API Key

Create a `.env` file and add:
```
OPENAI_API_KEY="sk-your-deepseek-api-key"

# Optional: Add Google Cookie for Google search
# GOOGLE_COOKIE="your-google-cookie-here"
```

### How to Get Google Cookie (Optional)

If you want to use Google search, you need to configure Cookie:

1. Open your browser and visit https://www.google.com
2. Open Developer Tools (F12)
3. Switch to the Network tab
4. Search for anything on Google
5. Find the first request and check Request Headers
6. Copy the complete Cookie value
7. Add to `.env` file:
   ```
   GOOGLE_COOKIE="NID=xxx; 1P_JAR=xxx; ..."
   ```

**Note**: Cookies expire. If Google search fails, you may need to update the Cookie.

## Usage

Run the main program:
```bash
python main.py
```

Or:
```bash
python3 main.py
```

## About Search Engines

This project supports three search engines:

### ğŸ” Search Engine Priority

1. **Google** (requires Cookie configuration)
   - âœ… Highest search quality
   - âœ… Wide international news coverage
   - âš ï¸ Requires Cookie configuration (see above)
   - âš ï¸ Cookie expires, needs periodic updates

2. **Baidu News** (default)
   - âœ… Stable and reliable, no configuration needed
   - âœ… Good Chinese news quality
   - âœ… No Cookie or API Key required

3. **Bing** (backup)
   - âœ… Last resort option
   - âš ï¸ May be limited by anti-crawling

### ğŸ’¡ Recommended Configuration

- **Daily Use**: Don't configure GOOGLE_COOKIE, use Baidu (stable)
- **Quality Priority**: Configure GOOGLE_COOKIE, prioritize Google
- **International News**: Configure GOOGLE_COOKIE, Google has better international coverage

## Workflow

1. **Search Phase**: Intelligently combine Google, Baidu News, and Bing to search for relevant news links (auto-deduplication)
2. **Crawl Phase**: Extract article titles and content using Newspaper3k
3. **Deduplication Phase**: Remove duplicate articles using fuzzy matching algorithm
4. **Map Phase**: Generate independent summaries for each article
5. **Reduce Phase**: Consolidate all summaries and extract key information
6. **Report Generation**: Generate HTML report with summary, themes, entities, and timeline, saved to `reports/` directory

## Output

All generated HTML reports are saved in the `reports/` directory with the filename format:
```
{keyword}_{timestamp}.html
```

Example: `CHINA_20251118_211030.html`

## Tech Stack

- **AI Model**: DeepSeek-V3
- **GUI Framework**: PyQt6
- **Crawler Libraries**: Newspaper3k (Static), Selenium (Dynamic), BeautifulSoup4
- **Search Engines**: Google Search, Baidu News, Bing Search
- **Deduplication Algorithm**: FuzzyWuzzy (Levenshtein Distance)
- **Architecture Pattern**: Map-Reduce

## License

MIT License

## Author

Shane
